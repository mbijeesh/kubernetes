Docker Image - package Template from which we can run multiple containers.
Node: Is a virtual or physical mchine where k8s is running. To avoid SPOF, use multiple nodes. So 3 nodes can form a k8s cluster.
Multiple nodes in cluster can share load as well. 
There is a master node in  the cluster which will decide in which worker node a container should run. 
So master node is the orchestration manager. 
K8s - installs :- 
API Server - Running on master node.  To interact with the k8s cluster by user. From the master node it communicate with the kubelet/agent in other worker nodes and carry out 
  the action requested by the worker node. 
etcd -  key value store, to store the information about mutiple nodes in a distributed manner. Will ensure no conflicts with the master. 
scheduler -   Running on master node. Assign the new container to nodes. 
controller  - Running on master node. Take decision when a node goes down and distribute the containers to other nodes. 
Container runtime - Running on the worker node. The container software, in our case the docker.  
kubelet  - the agent runs on each worker node in the cluster. It  ensuer the containers are running on the node as expected. 
# kubectl - command line interface  - can be 1 version difference with cluster. 

kubectl run hello-minikube
kubectl cluster-info
kubectl get nodes
-----
Docker is NOW not a supported  container run time. Though docker can be used for creating pods using containerd. 
ctl - very basic CLI 
nerdctl - docker like cli for 
crictl - CLI fro managing Containers mainly  for debug. Don't use with kubelet in K8S.
-----
Ways to setup/configure k8s:
Minikube  - single node k8s cluster  ( Try https://minikube.sigs.k8s.io/docs/start/)
microk8s 
kubeadm - to set up multi node  k8s cluster in local
ALso available in GCP/AWS/Azure
--
Minikube - comes with all services inside one bundle as a single node k8s cluster
can be download from internet
Then use virtual box. 
--

Before set up  we need to install kubectl 
https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/  
Check virtualization enabled 
grep -E --color 'vmx|svm' /proc/cpuinfo  
Install virtualbox in your ubuntu/windows laptop.
The minikube installation in windows/linux create the VM automatically inside the virtual box.
See documentation 
minikube status
kubectl get nodes
#kubectl creaet deployment <name>  <image path>

#kubectl get deployments

#kubectl expose deploymnet <name> --type --port=
#minikube service name --url    > will give  the URL
#kubectl get pods
Access it, 
Now delete the service:
#kubectl delete services <name>
delet the deploymnet
#kubectl delete deployment <name>
#kubectl get pods ( it shows terminating )

pod is smallest entity that you can manage in k8s
When the load increases,  add  new pod
To again  increase, add a new node in the cluster and add new pod. 
A pod has the one to one relationship with the container running your application. To scale up create new pod and to scale down , just delete the  pod.
No need to add additional container in the pod.

Two containers can be a part of one pod. So that when a  application+supportapplication  need scale up, just add new pod which already contains both containers 
 - application and the support application.
 
 In docker, consider below scenario - 
    For One application one container started, and scaled up to 5 
    Also there is a supportapp container, which also scaled to 5.  Now there is a manual task to map the link between one app to its support app container. 
    But k8s will take this work fo us. 
    
   ----
   kubectl run nginx --image=nginx  (  will download image from docker hub)
   #kubectl getpods
   #kubectl getpods -o wide
   #kubectl describe pod nginx
   Kubernetes Concepts - https://kubernetes.io/docs/concepts/

Also, we can create a yaml file using below command
#kubectl run nginx --image=nginx --dry-run=client -o yaml > nginx.yaml
#kubectl create -f nginx.yaml
# kubectl edit 

Pod Overview- https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/
---
Replica set:
For high availability 
For load balancing/scaling
replicaset-definition.yaml

To Define template of a pod. 
Use the pod definition from metadata and copy as a child under the 
template metadata.
apiVersion: apps/v1
kind: ReplicaSet
metadata: 
  name:my-app-replicaset
  labels:
    app: myapp
    type: dev
spec:
  template:  # from here, till image - just copied from pod definition. 
    metadata:
      name: myapp-prod
      labels:
        app: myapp
        type: dev
    spec: 
      containers:
      - name: nginx
        image: nginx
  replicas: 3
  selector: 
    matchLabels: 
      type: dev

## the above yaml will create a replicaset and which will run 3 pods.
#kubectl create -f replicaset-definition.yaml
#kubectl get replicaset
If we want to scal up, just change the number 3 to 4 and 
#kubectl replace -f replicaset-definition.yaml 
Without modifying the file, to scale temporarily,use below command
#kubectl scale --replicas=6 -f  replicaset-definition.yaml
#kubectl scale --replicas=6  replicaset myapp-replicaset

#kubectl get replicaset
#kubectl delete replicaset myapp-replicaset  (also delete the pods)
In replicaset, if we delete one pod, it will recreate. 
#kubectl edit  > edit the file in memory , not the actual file. So changes applied immediate.
---------------























